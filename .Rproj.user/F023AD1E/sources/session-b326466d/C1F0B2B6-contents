---
title: "Sarcasm/irony project"
output: html_document
date: "2025-03-18"
---

```{r setup, include=FALSE}
library(tidyverse)
library(here)
library(bayestestR)
library(bayesplot)
library(brms)
library(report)
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

syrett_theme <- function() {
  theme(
    axis.text = element_text(colour = "black", family = "Arial", size = 12),
    axis.title = element_text(colour = "black", family = "Arial", size = 12))
} 

tidy_data = read.csv(here("data", "tidy_data.csv")) %>% 
  filter(trial_number > 6) # removing practice trials 
```

<details>
  <summary>**Trial probe: Approve**</summary>

**Statistical Analysis**

This section contains the analysis for the trial probe "approve". First, the total proportion of responses (1 or 2) was compared as a function of intonation type (sarcastic or declarative). Next, the proportions of responses were compared according to the second predictor alone, "modifier_type" (3 levels: +gradable +subjective +valence adjectives, 
+gradable +subjective –valence adjective, 
–gradable –subjective adjectives/nouns). 
Finally, both predictors are visualized and considered in tandem as they relate to the responses of 1 or 2. 

In each case, a Bayesian multilevel logistic regression was run in which the binary outcome (log-odds of choosing 2) was analyzed as a function of the relevant predictors (detailed below) and a random intercept for subject id, trial object, and trial modifier. 
Each model was estimated using MCMC
sampling with 4 chains of 2000 iterations and a warmup of 1000
Hamiltonian Monte-Carlo sampling was carried out distributed between 6 processing cores.

**Intonation only**

```{r, include=FALSE}
approve_df = tidy_data %>% 
  filter(probe_type == "approve") 

pcts_app = approve_df %>% group_by(intonation, response) %>% summarise(n = round(n()/834, digits = 2)*100)
```

```{r}
approve_df %>% 
  ggplot(aes(intonation, fill = as.factor(response), group = as.factor(response))) + 
  geom_bar(position = "fill", color = "black") +
  theme_minimal() + syrett_theme() + scale_fill_discrete(name = "Response") + ggtitle("Overall proportion of responses to declarative and sarcastic items")

```

The first plot shows the overall proportion of responses to declarative and sarcastic items (before taking other conditions into account).
Overall, coding of 2 was slightly more frequent for the declarative items (`r pcts_app$n[2]` percent) compared to `r pcts_app$n[4]` percent in sarcastic responses.

A logistic regression model was fit in which response was predicted as a function of intonation (including the random effects mentioned above). 
The model, described below, found substantial evidence that the overall difference between responses to sarcastic and declarative items was not due to chance (probability of direction approaching 1).
The table below shows the predicted log-odds for a selection of 1 for the declarative condition (represented by the intercept in the first row) and the effect (change in log-odds) of sarcastic (second row).
The negative effect suggests that a selection of 1 is less likely for sarcastic items than declarative ones.

```{r}
approve_mod_int = brms::brm(response ~ intonation + (1 | subject.ID) + 
                       (1 | trial_object) + (1 | trial_modifier),
                     family = "bernoulli",
                     data = approve_df,
                     file = here("data", "models", "approve_mod_intonation_on;y.rds"))

describe_posterior(
  approve_mod_int,
  effects = "fixed",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>%
  as.data.frame() %>% 
  mutate(across(where(is.numeric), round, 3)) %>% 
  knitr::kable(row.names = FALSE)
```

**Modifier type only**

```{r}
approve_df %>% 
  ggplot(aes(modifier_type, fill = as.factor(response), group = as.factor(response))) + 
  geom_bar(position = "fill", color = "black") +
  theme_minimal() + syrett_theme() + scale_fill_discrete(name = "Response") + ggtitle("Overall proportion of responses to the modifier types")
```

```{r, include=FALSE}
pcts_app_mod = approve_df %>% group_by(modifier_type, response) %>% summarise(n = round(n()/556, digits = 2)*100)
```

This plot shows the overall proportion of responses to the three modifier types .
Overall, coding of 2 was most frequent for the `grad+subj+pos` items (`r pcts_app_mod$n[4]` percent), followed by `–grad–subj` with `r pcts_app_mod$n[6]` percent of responses of 2.
Finally, `grad+subj+neg` showed very few responses of 2 (only `r pcts_app_mod$n[2]` percent).

A logistic regression model was fit in which response was predicted as a function of modifier type (including the random effects mentioned above). 


The model, described below, found substantial evidence that, relative to the baseline `–grad–subj`, there was compelling evidence that both of the other modifier types were distinctly responded to by participants. 
The table below shows the predicted log-odds for a selection of 1 for the `grad–subj` condition (represented by the intercept in the first row).
The model predicts that a choice of 1 for `modifier_typegradPsubjPneg` (second row) relative to `grad–subj` is lower overall.
The opposite was found for the modifier type `b_modifier_typegradPsubjPpos` relative to `grad-subj`, in which the log-odds of a choice of 1 was higher.

```{r}
approve_mod_int_mt = brms::brm(response ~ modifier_type + (1 | subject.ID) + 
                       (1 | trial_object) + (1 | trial_modifier),
                     family = "bernoulli",
                     data = approve_df,
                     file = here("data", "models", "approve_mod_mod_type_only.rds"))

describe_posterior(
  approve_mod_int_mt,
  effects = "fixed",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>%
  as.data.frame() %>% 
  mutate(across(where(is.numeric), round, 3)) %>% 
  knitr::kable(row.names = FALSE)
```

**Intonation and Modifier type**

```{r}
approve_df %>% 
  ggplot(aes(modifier_type, fill = as.factor(response), group = as.factor(response))) + 
  geom_bar(position = "fill", color = "black") + facet_wrap(~intonation) +
  theme_minimal() + syrett_theme() + scale_fill_discrete(name = "Response") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r, include=FALSE}
approve_all = approve_df %>% group_by(intonation, response, modifier_type) %>% summarise(n = round(n()/278, digits = 2))

```

Please see a descriptive summary of each of the six cases below:

When the intonation was `r approve_all$intonation[1]` and the modifier type was `r approve_all$modifier_type[1]`, `r approve_all$n[1]` percent of responses were `r approve_all$response[1]`.

When the intonation was `r approve_all$intonation[2]` and the modifier type was `r approve_all$modifier_type[2]`, `r approve_all$n[2]` percent of responses were `r approve_all$response[2]`.

When the intonation was `r approve_all$intonation[3]` and the modifier type was `r approve_all$modifier_type[3]`, `r approve_all$n[3]` percent of responses were `r approve_all$response[3]`.

When the intonation was `r approve_all$intonation[7]` and the modifier type was `r approve_all$modifier_type[7]`, `r approve_all$n[7]` percent of responses were `r approve_all$response[7]`.

When the intonation was `r approve_all$intonation[8]` and the modifier type was `r approve_all$modifier_type[8]`, `r approve_all$n[8]` percent of responses were `r approve_all$response[8]`.

When the intonation was `r approve_all$intonation[9]` and the modifier type was `r approve_all$modifier_type[9]`, `r approve_all$n[9]` percent of responses were `r approve_all$response[9]`.

The final model is a little more complex than the first two, since we now have an interaction. 
This model predicts to log-odds of a response of as a function of both intonation (2 levels) and modifier type (3 levels) and their interaction. 
As a result, the intercept of this model represents the log-odds of a choice of 1 when the modifier type is `grad–subj` and the intonation is `declarative`. 
The fixed effect `b_intonationsarcastic` represents the change in the predicted log-dds of choosing 1 when we change the predictor for intonation from `declarative` to `sarcastic`. It's negative, which suggests that it the probality of choosing 1 is less for sarcastic intonation relative to declarative when the modifier type is `grad–subj`. 
Rows 3 and 4 make similar adjustments, but this time change modifier type while holding the intonation constant. 
The final two terms are the interaction terms. 
These represent the change relative to the declarative modifier combinations. The positve estimate for row 5 suggests that the probability of choosing 1 when the modifier type is `grad+subj+neg` is higher for when the intonation is sarcastic than declarative. 
The negative value for row 6 suggests that the probability of choosing 1 when the modifier type is `grad+subj+pos` is lower for when the intonation is sarcastic than declarative. 
In each comparison, the row "pd" (probability of direction) tell us how sure we can be about the given comparison. In this case, all of the comparisons' directions are highly probable (over .95). 

```{r}
approve_mod = brms::brm(response ~ intonation*modifier_type + (1 | subject.ID) + 
                       (1 | trial_object) + (1 | trial_modifier),
                     family = "bernoulli",
                     data = approve_df,
                     file = here("data", "models", "approve_mod.rds"))

describe_posterior(
  approve_mod,
  effects = "fixed",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>%
  as.data.frame() %>% 
  mutate(across(where(is.numeric), round, 3)) %>% 
  knitr::kable(row.names = FALSE)
```

</details> 

<details>
  <summary>**Trial probe: Mean**</summary>
  
**Statistical Analysis**

This analysis is essentially the same as the "approve section". For the sake of brevity, I've made tables and plots only - let me know if I should add similar interpretations as I've done above. 

  
```{r}
mean_df = tidy_data %>% 
  filter(probe_type == "mean") 

mean_mod = brms::brm(response ~ intonation*modifier_type + (1 | subject.ID) + 
                            (1 | trial_object) + (1 | trial_modifier),
                          family = "bernoulli",
                          data = mean_df,
                     file = here("data", "models", "mean_mod.rds"))

```


```{r, include=FALSE}
pcts_mean = mean_df %>% group_by(intonation, response) %>% summarise(n = round(n()/834, digits = 2)*100)
```

```{r}
mean_df %>% 
  ggplot(aes(intonation, fill = as.factor(response), group = as.factor(response))) + 
  geom_bar(position = "fill", color = "black") +
  theme_minimal() + syrett_theme() + scale_fill_discrete(name = "Response") + ggtitle("Overall proportion of responses to declarative and sarcastic items")

```

The first plot shows the overall proportion of responses to declarative and sarcastic items (before taking other conditions into account).
Again (like "approve" itmes), coding of 2 was more frequent for the declarative items (`r pcts_mean$n[2]` percent) compared to `r pcts_mean$n[4]` percent in sarcastic responses.


**Note: This is exactly the same as the approve section**

A logistic regression model was fit in which response was predicted as a function of intonation (including the random effects mentioned above). 
The model, described below, found substantial evidence that the overall difference between responses to sarcastic and declarative items was not due to chance (probability of direction approaching 1).
The table below shows the predicted log-odds for a selection of 1 for the declarative condition (represented by the intercept in the first row) and the effect (change in log-odds) of sarcastic (second row).
The negative effect suggests that a selection of 1 is less likely for sarcastic items than declarative ones.

```{r}
mean_mod_int = brms::brm(response ~ intonation + (1 | subject.ID) + 
                       (1 | trial_object) + (1 | trial_modifier),
                     family = "bernoulli",
                     data = mean_df,
                     file = here("data", "models", "mean_mod_intonation_on;y.rds"))

describe_posterior(
  mean_mod_int,
  effects = "fixed",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>%
  as.data.frame() %>% 
  mutate(across(where(is.numeric), round, 3)) %>% 
  knitr::kable(row.names = FALSE)
```

**Modifier type only**

```{r}
mean_df %>% 
  ggplot(aes(modifier_type, fill = as.factor(response), group = as.factor(response))) + 
  geom_bar(position = "fill", color = "black") +
  theme_minimal() + syrett_theme() + scale_fill_discrete(name = "Response") + ggtitle("Overall proportion of responses to the modifier types")
```

```{r, include=FALSE}
pcts_mean_mod = mean_df %>% group_by(modifier_type, response) %>% summarise(n = round(n()/556, digits = 2)*100)
```

This plot shows the overall proportion of responses to the three modifier types .
Overall, coding of 2 was most frequent for the `grad+subj+neg` items (`r pcts_app_mod$n[2]` percent), followed by `–grad–subj` with `r pcts_app_mod$n[6]` percent of responses of 2.
Finally, `grad+subj+pos` showed very few responses of 2 (only `r pcts_app_mod$n[4]` percent).

A logistic regression model was fit in which response was predicted as a function of modifier type (including the random effects mentioned above). 

The model, described below, found substantial evidence that, relative to the baseline `–grad–subj`, there was compelling evidence that both of the other modifier types were distinctly responded to by participants. 
The table below shows the predicted log-odds for a selection of 1 for the `grad–subj` condition (represented by the intercept in the first row).
The model predicts that a choice of 1 for `modifier_typegradPsubjPneg` (second row) relative to `grad–subj` is higher overall.
The opposite was found for the modifier type `b_modifier_typegradPsubjPpos` relative to `grad-subj`, in which the log-odds of a choice of 1 was lower

```{r}
mean_mod_int_mt = brms::brm(response ~ modifier_type + (1 | subject.ID) + 
                       (1 | trial_object) + (1 | trial_modifier),
                     family = "bernoulli",
                     data = mean_df,
                     file = here("data", "models", "mean_mod_mod_type_only.rds"))

describe_posterior(
  mean_mod_int_mt,
  effects = "fixed",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>%
  as.data.frame() %>% 
  mutate(across(where(is.numeric), round, 3)) %>% 
  knitr::kable(row.names = FALSE)
```

**Intonation and Modifier type**

```{r}
mean_df %>% 
  ggplot(aes(modifier_type, fill = as.factor(response), group = as.factor(response))) + 
  geom_bar(position = "fill", color = "black") + facet_wrap(~intonation) +
  theme_minimal() + syrett_theme() + scale_fill_discrete(name = "Response") +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

```{r, include=FALSE}
mean_all = mean_df %>% group_by(intonation, response, modifier_type) %>% summarise(n = round(n()/278, digits = 2))
```

Please see a descriptive summary of each of the six cases below:

When the intonation was `r mean_all$intonation[1]` and the modifier type was `r mean_all$modifier_type[1]`, `r mean_all$n[1]` percent of responses were `r mean_all$response[1]`.

When the intonation was `r mean_all$intonation[2]` and the modifier type was `r mean_all$modifier_type[2]`, `r mean_all$n[2]` percent of responses were `r mean_all$response[2]`.

When the intonation was `r mean_all$intonation[3]` and the modifier type was `r mean_all$modifier_type[3]`, `r mean_all$n[3]` percent of responses were `r mean_all$response[3]`.

When the intonation was `r mean_all$intonation[7]` and the modifier type was `r mean_all$modifier_type[7]`, `r mean_all$n[7]` percent of responses were `r mean_all$response[7]`.

When the intonation was `r mean_all$intonation[8]` and the modifier type was `r mean_all$modifier_type[8]`, `r mean_all$n[8]` percent of responses were `r mean_all$response[8]`.

When the intonation was `r mean_all$intonation[9]` and the modifier type was `r mean_all$modifier_type[9]`, `r mean_all$n[9]` percent of responses were `r mean_all$response[9]`.

Like the previous model with an interaction (for "approve"), this model predicts to log-odds of a response of as a function of both intonation (2 levels) and modifier type (3 levels) and their interaction. 
As a result, the intercept of this model represents the log-odds of a choice of 1 when the modifier type is `grad–subj` and the intonation is `declarative`. 
The fixed effect `b_intonationsarcastic` represents the change in the predicted log-dds of choosing 1 when we change the predictor for intonation from `declarative` to `sarcastic`. It's negative, which suggests that it the probality of choosing 1 is less for sarcastic intonation relative to declarative when the modifier type is `grad–subj`. 
Rows 3 and 4 make similar adjustments, but this time change modifier type while holding the intonation constant. 
The final two terms are the interaction terms. 
These represent the change relative to the declarative modifier combinations. The negative estimate for row 5 suggests that the probability of choosing 1 when the modifier type is `grad+subj+neg` is lower for when the intonation is sarcastic than declarative. 
The negative value for row 6 suggests that the probability of choosing 1 when the modifier type is `grad+subj+pos` is lower for when the intonation is sarcastic than declarative. 
This model does not provide compelling evidence for each comparison (see the "pd" column - those lower than .95 are uncertain).

```{r}
mead_mod = brms::brm(response ~ intonation*modifier_type + (1 | subject.ID) + 
                       (1 | trial_object) + (1 | trial_modifier),
                     family = "bernoulli",
                     data = mean_df,
                     file = here("data", "models", "mean_mod.rds"))

describe_posterior(
  mead_mod,
  effects = "fixed",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>%
  as.data.frame() %>% 
  mutate(across(where(is.numeric), round, 3)) %>% 
  knitr::kable(row.names = FALSE)
```


</details> 

<details>
  <summary>**Trial probe: nice**</summary>
```{r}
nice_df = tidy_data %>% 
  filter(probe_type == "nice") 

nice_df %>% 
  ggplot(aes(x = response)) + 
  geom_bar(position = "dodge", color = "black") + facet_grid(modifier_type~intonation) +
  theme_minimal() + syrett_theme()

nice_mod = brms::brm(response ~ intonation*modifier_type + (1 | subject.ID) + 
                          (1 | trial_object) + (1 | trial_modifier),
                        family = "categorical",
                        data = nice_df, 
                     file = here("data", "models", "nice_mod.rds"))
```

```{r}
ce_df = conditional_effects(nice_mod, categorical = TRUE)[["modifier_type:cats__"]]


```

```{r}
describe_posterior(
  nice_mod,
  effects = "fixed",
  component = "all",
  test = c("p_direction", "p_significance"),
  centrality = "all"
) %>%
  as.data.frame() %>% 
  mutate(across(where(is.numeric), round, 3)) %>% 
  knitr::kable(row.names = FALSE)
```
```

</details> 